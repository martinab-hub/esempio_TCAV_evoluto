{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinab-hub/esempio_TCAV_evoluto/blob/main/esempio_TCAV_evoluto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qxllJ-2tK7p"
      },
      "source": [
        "**Show cases Testing with Concept Activation Vectors (TCAV) on Imagenet Dataset and GoogleNet model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YRB6DTftJh1"
      },
      "source": [
        "This tutorial shows how to apply TCAV, a concept-based model interpretability algorithm, on a classification task using GoogleNet model and imagenet dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z_gp3AENV2Hs",
        "outputId": "2d2a3ae5-88fb-4c8d-8f22-c57ef460ff1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6->captum) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (3.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: tcav in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: matplotlib>=2.2.4 in /usr/local/lib/python3.10/dist-packages (from tcav) (3.7.1)\n",
            "Requirement already satisfied: Pillow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tcav) (10.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from tcav) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from tcav) (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tcav) (3.20.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.4->tcav) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.4->tcav) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.4->tcav) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.4->tcav) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.4->tcav) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.4->tcav) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.4->tcav) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.4->tcav) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.3->tcav) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.3->tcav) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.4->tcav) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Tutti i pacchetti sono stati installati correttamente.\n"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install captum\n",
        "!pip install torch torchvision\n",
        "!pip install tcav\n",
        "\n",
        "!pip install matplotlib\n",
        "!pip install Pillow\n",
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install protobuf\n",
        "!pip install pandas\n",
        "\n",
        "# Messaggio di conferma per l'installazione dei pacchetti\n",
        "print(\"Tutti i pacchetti sono stati installati correttamente.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Oz9aBumtZf7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# ..........torch imports............\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "#.... Captum imports..................\n",
        "from captum.attr import LayerGradientXActivation, LayerIntegratedGradients\n",
        "\n",
        "from captum.concept import TCAV\n",
        "from captum.concept import Concept\n",
        "from captum.concept import Classifier\n",
        "\n",
        "from captum.concept._utils.data_iterator import dataset_to_dataloader, CustomIterableDataset\n",
        "from captum.concept._utils.common import concepts_to_str\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SUe7hQXtdeK"
      },
      "source": [
        "Defining image related transformations and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3HP0bPw2th-i"
      },
      "outputs": [],
      "source": [
        "# Method to normalize an image to Imagenet mean and standard deviation\n",
        "def transform(img):\n",
        "\n",
        "    return transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "            ),\n",
        "        ]\n",
        "    )(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "La8xyGnBtk9v"
      },
      "outputs": [],
      "source": [
        "def get_tensor_from_filename(filename):\n",
        "    img = Image.open(filename).convert(\"RGB\")\n",
        "    return transform(img)\n",
        "\n",
        "\n",
        "def load_image_tensors(class_name, root_path='/content/tcav_project', transform=True):\n",
        "    path = os.path.join(root_path, class_name)\n",
        "    filenames = glob.glob(path + '/*.jpg')\n",
        "\n",
        "    tensors = []\n",
        "    for filename in filenames:\n",
        "        img = Image.open(filename).convert('RGB')\n",
        "        tensors.append(transform(img) if transform else img)\n",
        "\n",
        "    return tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o5jhVmD6tmoY"
      },
      "outputs": [],
      "source": [
        "def assemble_concept(name, id, concepts_path=\"/content/tcav_project/\"):\n",
        "    concept_path = os.path.join(concepts_path, name) + \"/\"\n",
        "    dataset = CustomIterableDataset(get_tensor_from_filename, concept_path)\n",
        "    concept_iter = dataset_to_dataloader(dataset)\n",
        "\n",
        "    return Concept(id=id, name=name, data_iter=concept_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsPkgAiNtuDB"
      },
      "source": [
        "Let's assemble concepts into Concept instances using Concept class and concept images.\n",
        "\n",
        "In this case we define five concepts: three out of five are related to image texture and patterns such as striped, zigzagged and dotted, the other two represent random concepts.\n",
        "\n",
        "This code will:\n",
        "\n",
        "*  Download the Broden dataset and the zebra concept from imagenet\n",
        "*   Create random folders to be used by TCAV for statistical significance testing.\n",
        "*   Create concept and target datasets from Imagenet and Broden and organize them in a TCAV readable structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "edMc6V8Vl666",
        "outputId": "6bfe5e12-28e6-402f-d645-595b89ba1b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tcav' already exists and is not an empty directory.\n",
            "/content/tcav\n",
            "CONTRIBUTING.md        LICENSE\t  requirements.txt  Run_TCAV_on_colab.ipynb  tcav\n",
            "FetchDataAndModels.sh  README.md  Run_TCAV.ipynb    setup.py\n"
          ]
        }
      ],
      "source": [
        "# Clone the entire repo.\n",
        "!git clone https://github.com/tensorflow/tcav.git tcav\n",
        "%cd tcav\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4md4rTbmCyY",
        "outputId": "efac0838-24b9-4d22-f615-31a4b9d2e2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tcav/tcav/tcav_examples/image_models/imagenet\n",
            "Downloaded 50 for zebra\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "%cd /content/tcav/tcav/tcav_examples/image_models/imagenet\n",
        "%run download_and_make_datasets.py --source_dir='/content/tcav_project' --number_of_images_per_folder=50 --number_of_random_folders=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ6Eiuizta5N"
      },
      "outputs": [],
      "source": [
        "# Save data in drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#!mkdir -p '/content/drive/MyDrive/tcav_dataset' && cp -r /content/tcav_project '/content/drive/MyDrive/tcav_dataset'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEF_qDIduHWd"
      },
      "source": [
        "Now we have the dataset ready:\n",
        "\n",
        "there are in total 120 images for each of the striped, zigzagged and dotted concepts;\n",
        "then we randomly sample 4 diffent sets of 120 random images from imagenet dataset.\n",
        "\n",
        "We can now associate the images to the corrisponding concept:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vJNzNNlssaa"
      },
      "outputs": [],
      "source": [
        "concepts_path = \"/content/tcav_project\" #\"data/tcav/image/concepts/\"\n",
        "\n",
        "stripes_concept = assemble_concept(\"striped\", 0, concepts_path=concepts_path)\n",
        "zigzagged_concept = assemble_concept(\"zigzagged\", 1, concepts_path=concepts_path)\n",
        "dotted_concept = assemble_concept(\"dotted\", 2, concepts_path=concepts_path)\n",
        "\n",
        "\n",
        "random_0_concept = assemble_concept(\"random500_0\", 3, concepts_path=concepts_path)\n",
        "random_1_concept = assemble_concept(\"random500_1\", 4, concepts_path=concepts_path)\n",
        "\n",
        "concepts = {}           # dir = {concept_name, concept_object} e.g. {'cingolo_ant': Concept(0, 'Cingolo ANT'), ...}\n",
        "concepts['striped'] = stripes_concept\n",
        "concepts['zigzagged'] = zigzagged_concept\n",
        "concepts['dotted'] = dotted_concept\n",
        "\n",
        "\n",
        "random_concepts = {}\n",
        "random_concepts['random500_0'] = random_0_concept\n",
        "random_concepts['random500_1'] = random_1_concept\n",
        "\n",
        "concepts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-fpzDhtgfE6"
      },
      "outputs": [],
      "source": [
        "random_concepts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FXQ9FFn7p0C3"
      },
      "outputs": [],
      "source": [
        "# Let's visualize some samples from those concepts:\n",
        "\n",
        "n_figs = 5\n",
        "n_concepts = 5\n",
        "\n",
        "fig, axs = plt.subplots(n_concepts, n_figs + 1, figsize = (25, 4 * n_concepts))\n",
        "\n",
        "for c, concept in enumerate([stripes_concept, zigzagged_concept, dotted_concept, random_0_concept, random_1_concept]):\n",
        "    concept_path = os.path.join(concepts_path, concept.name) + \"/\"\n",
        "    img_files = glob.glob(concept_path + '*')\n",
        "    for i, img_file in enumerate(img_files[:n_figs + 1]):\n",
        "        if os.path.isfile(img_file):\n",
        "            if i == 0:\n",
        "                axs[c, i].text(1.0, 0.5, str(concept.name), ha='right', va='center', family='sans-serif', size=24)\n",
        "            else:\n",
        "                img = plt.imread(img_file)\n",
        "                axs[c, i].imshow(img)\n",
        "\n",
        "            axs[c, i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_nYO4-Kysaf"
      },
      "outputs": [],
      "source": [
        "# Load sample images from folder\n",
        "zebra_imgs = load_image_tensors('zebra', transform=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzPV42f28_cM"
      },
      "source": [
        "Visualizing some of the images that we will use for making predictions and explaining those predictions by the means of concepts defined above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kJfB0H5l9CO2"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 5, figsize = (25, 5))\n",
        "axs[0].imshow(zebra_imgs[34])\n",
        "axs[1].imshow(zebra_imgs[32])\n",
        "axs[2].imshow(zebra_imgs[30])\n",
        "axs[3].imshow(zebra_imgs[28])\n",
        "axs[4].imshow(zebra_imgs[26])\n",
        "\n",
        "axs[0].axis('off')\n",
        "axs[1].axis('off')\n",
        "axs[2].axis('off')\n",
        "axs[3].axis('off')\n",
        "axs[4].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQQOvaMO9Dxi"
      },
      "source": [
        "Here we perform a transformation and convert the images into tensors, so that we can use them as inputs to NN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb30BS7X9FQj"
      },
      "outputs": [],
      "source": [
        "# Load sample images from folder\n",
        "zebra_tensors = torch.stack([transform(img) for img in zebra_imgs])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn1o4BzTrHJn"
      },
      "source": [
        "**Defining GoogleNet Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UvTA0BkNvPLm"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.googlenet(pretrained=True)\n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiyhvyaxvRSC"
      },
      "source": [
        "**Computing TCAV Scores**\n",
        "\n",
        "Let's create TCAV class by passing the instance of GoogleNet model, a custom classifier and the list of layers where we would like to test the importance of concepts.\n",
        "\n",
        "The custom classifier, with a default implementation of Custom Classifier, will be trained to learn classification boundaries between concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqozAmTPkhc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_layers_name(model: torch.nn.Module):\n",
        "    \"\"\"List the names of the layers in a module including nested ones.\n",
        "\n",
        "    Args:\n",
        "      model: A target PyTorch model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    layers_list = []\n",
        "    for name, layer in model.named_modules():\n",
        "        layers_list.append(name)\n",
        "    return layers_list\n",
        "\n",
        "\n",
        "def get_hidden_activation(model: torch.nn.Module,\n",
        "                          layer_name,\n",
        "                          input_data: torch.Tensor):\n",
        "    \"\"\"Get intermediate activations PyTorch model\n",
        "\n",
        "    Args:\n",
        "      model: A target PyTorch model.\n",
        "      layer_name: Name of the layer of interest.\n",
        "      input_data: Input passed to the PyToch model\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    activations = {}\n",
        "\n",
        "    def get_hidden_activations(name):\n",
        "        def hook(module, input, output):\n",
        "            activations[name] = output\n",
        "        return hook\n",
        "\n",
        "    # Attach hooks to the layers whose activations you want to capture\n",
        "    desired_layer = getattr(model, layer_name, None)\n",
        "    if desired_layer is None:\n",
        "        raise ValueError(f\"Layer '{layer_name}' not found in the model.\")\n",
        "\n",
        "    hook = desired_layer.register_forward_hook(\n",
        "        get_hidden_activations(layer_name))\n",
        "\n",
        "    # Perform a forward pass to capture intermediate activations\n",
        "    model(input_data)\n",
        "\n",
        "    # Detach the hook after capturing activations\n",
        "    hook.remove()\n",
        "\n",
        "    # Access the intermediate activations from the 'activations' dictionary\n",
        "    activation = activations[layer_name]\n",
        "\n",
        "    return activation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BKu5wSkQkmiR"
      },
      "outputs": [],
      "source": [
        "# layers = get_layers_name(model)\n",
        "layers=['inception4c', 'inception4d', 'inception4e']\n",
        "#layers = ['conv1', 'maxpool1', 'inception_3a', 'inception_3b', 'inception_4a', 'inception_4b', 'inception_4c', 'inception_4d', 'inception_4e', 'inception_5a', 'inception_5b', 'avgpool', 'fc']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kVQoO4cRdgGc"
      },
      "outputs": [],
      "source": [
        "activations = {}\n",
        "# Loop through the layers to extract activations and analyze them\n",
        "for layer_name in layers:\n",
        "    # Get activations for this layer\n",
        "    activation = get_hidden_activation(model, layer_name, zebra_tensors)\n",
        "\n",
        "    # Flatten the activations if necessary\n",
        "    activations[layer_name] = activation.view(activation.size(0), -1)\n",
        "\n",
        "activations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "huBnCAEmbWBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYmB_ErlhxZN"
      },
      "outputs": [],
      "source": [
        "# Prepare the activations and labels for the classifier\n",
        "activation_data = []\n",
        "labels = []\n",
        "\n",
        "for concept_name, concept in concepts.items():\n",
        "    # Loop through each concept's data iterator and load activations\n",
        "    for data in concept.data_iter:\n",
        "        # Check the shape of 'data' before adding extra dimensions\n",
        "        if len(data.shape) == 3:  # If data is [3, 224, 224]\n",
        "            data = data.unsqueeze(0)  # Add batch dimension to become [1, 3, 224, 224]\n",
        "\n",
        "        # Move data to the correct device and get hidden activation\n",
        "        activation = get_hidden_activation(model, layer_name, data.to(device)).detach().cpu()\n",
        "\n",
        "        # Flatten and add activation data\n",
        "        activation_data.append(activation.view(-1).numpy())\n",
        "        labels.append(concept.id)\n",
        "\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "activation_data = np.array(activation_data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "## Train the Classifier (Logistic Regression)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(activation_data, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_fUbnP8fx0n8"
      },
      "outputs": [],
      "source": [
        "mytcav = TCAV(model=model,\n",
        "              layers=layers,\n",
        "              classifier = classifier,\n",
        "              layer_attr_method = LayerIntegratedGradients(\n",
        "                model, None, multiply_by_inputs=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw3zlmPCynbL"
      },
      "source": [
        "Defining the  2 experimental sets for CAVs: [\"striped\", \"random_0\"] and [\"striped\", \"random_1\"].\n",
        "\n",
        "We will train a classifier for each experimal set that learns hyperplanes which separate the concepts in each experimental set from one another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0orbPjpPyoNn"
      },
      "outputs": [],
      "source": [
        "experimental_set_rand = {\n",
        "    concept_name: [[concept, random] for random in random_concepts.values()]\n",
        "    for concept_name, concept in concepts.items()\n",
        "}\n",
        "\n",
        "experimental_set_rand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c51xzhYP9HGq"
      },
      "outputs": [],
      "source": [
        "# zebra class index\n",
        "zebra_ind = 340\n",
        "\n",
        "scores_w_random = {}\n",
        "for c in concepts:\n",
        "    score_name = f'scores_{c}'\n",
        "    globals()[score_name] = mytcav.interpret(inputs = zebra_tensors,\n",
        "                                        experimental_sets = experimental_set_rand.get(c),\n",
        "                                        target = zebra_ind,\n",
        "                                        n_steps = 5,\n",
        "                                       )\n",
        "    scores_w_random.add[score_name] = globals()[score_name]\n",
        "\n",
        "scores_w_random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZNuFyu8nOJW"
      },
      "outputs": [],
      "source": [
        "scores_zigzagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqDe7I63nPso"
      },
      "outputs": [],
      "source": [
        "scores_dotted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sppiMF6i4vi"
      },
      "outputs": [],
      "source": [
        "scores_striped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2Faq53E9JSr"
      },
      "outputs": [],
      "source": [
        "# Auxiliary functions for visualizing of TCAV scores.\n",
        "def format_float(f):\n",
        "    return float('{:.3f}'.format(f) if abs(f) >= 0.0005 else '{:.3e}'.format(f))\n",
        "\n",
        "def plot_tcav_scores(experimental_sets, tcav_scores):\n",
        "    fig, ax = plt.subplots(1, len(experimental_sets), figsize = (25, 7))\n",
        "\n",
        "    barWidth = 1 / (len(experimental_sets[0]) + 1)\n",
        "\n",
        "    for idx_es, concepts in enumerate(experimental_sets):\n",
        "\n",
        "        concepts = experimental_sets[idx_es]\n",
        "        concepts_key = concepts_to_str(concepts)\n",
        "\n",
        "        pos = [np.arange(len(layers))]\n",
        "        for i in range(1, len(concepts)):\n",
        "            pos.append([(x + barWidth) for x in pos[i-1]])\n",
        "        _ax = (ax[idx_es] if len(experimental_sets) > 1 else ax)\n",
        "        for i in range(len(concepts)):\n",
        "            val = [format_float(scores['sign_count'][i]) for layer, scores in tcav_scores[concepts_key].items()]\n",
        "            _ax.bar(pos[i], val, width=barWidth, edgecolor='white', label=concepts[i].name)\n",
        "\n",
        "        # Add xticks on the middle of the group bars\n",
        "        _ax.set_xlabel('Set {}'.format(str(idx_es)), fontweight='bold', fontsize=16)\n",
        "        _ax.set_xticks([r + 0.3 * barWidth for r in range(len(layers))])\n",
        "        _ax.set_xticklabels(layers, fontsize=16)\n",
        "\n",
        "        # Create legend & Show graphic\n",
        "        _ax.legend(fontsize=16)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni0dJ7S69OXd"
      },
      "source": [
        "Let's use above defined auxilary functions and visualize tcav scores below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVPFlyR72PIk"
      },
      "outputs": [],
      "source": [
        "for c in concepts:\n",
        "    score_name = f'scores_{c}'\n",
        "    plot_tcav_scores(experimental_set_rand.get(c), score_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG6U_XT79OBE"
      },
      "outputs": [],
      "source": [
        "plot_tcav_scores(experimental_set_rand.get('striped'), scores_striped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfC7q-mP9RgE"
      },
      "source": [
        "Now, let's compute TCAV scores for a different experimental set that contains three different specific concepts such as striped, zigzagged and dotted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RdVwXR8pkII"
      },
      "outputs": [],
      "source": [
        "plot_tcav_scores(experimental_set_rand.get('dotted'), scores_dotted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li1_DklDppGt"
      },
      "outputs": [],
      "source": [
        "plot_tcav_scores(experimental_set_rand.get('zigzagged'), scores_zigzagged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChAtcRFt9TPx"
      },
      "outputs": [],
      "source": [
        "experimental_set_zig_dot = [[stripes_concept, zigzagged_concept, dotted_concept]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PjQ1Z_29Um_"
      },
      "outputs": [],
      "source": [
        "tcav_scores_w_zig_dot = mytcav.interpret(inputs=zebra_tensors,\n",
        "                                         experimental_sets=experimental_set_zig_dot,\n",
        "                                         target=zebra_ind,\n",
        "                                         n_steps=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHRkyjyVvBKh"
      },
      "outputs": [],
      "source": [
        "tcav_scores_w_zig_dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D5J73Gd9WNj"
      },
      "outputs": [],
      "source": [
        "plot_tcav_scores(experimental_set_zig_dot, tcav_scores_w_zig_dot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo8D87gY9ZGB"
      },
      "source": [
        "**Statistical significance testing of concepts**\n",
        "\n",
        "In order to convince ourselves that our concepts truly explain our predictions, we conduct statistical significance tests on TCAV scores by constructing a number of experimental sets.\n",
        "\n",
        "\n",
        "Each experimental set contains a random concept consisting of a number of random subsamples. In our case this allows us to estimate the robustness of TCAV scores by the means of numerous random concepts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "l8dwTEj59tP9"
      },
      "outputs": [],
      "source": [
        "n = 2\n",
        "random_concepts = [assemble_concept('random500_' + str(i+2), i+5) for i in range(0, n)]\n",
        "\n",
        "print(random_concepts)\n",
        "\n",
        "experimental_sets = [[stripes_concept, random_0_concept], [stripes_concept, random_1_concept]]\n",
        "\n",
        "experimental_sets.extend([[stripes_concept, random_concept] for random_concept in random_concepts])\n",
        "experimental_sets.append([random_0_concept, random_1_concept])\n",
        "experimental_sets.extend([[random_0_concept, random_concept] for random_concept in random_concepts])\n",
        "experimental_sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKj7dt4Y9vIZ"
      },
      "source": [
        "Now, let's define a convenience function for assembling the experiments together as lists of Concept objects, creating and running the TCAV:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6el82tc99wbf"
      },
      "outputs": [],
      "source": [
        "def assemble_scores(scores, experimental_sets, idx, score_layer, score_type):\n",
        "    score_list = []\n",
        "    for concepts in experimental_sets:\n",
        "        score_list.append(scores[\"-\".join([str(c.id) for c in concepts])][score_layer][score_type][idx])\n",
        "\n",
        "    return score_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkTEraxJ9yLX"
      },
      "source": [
        "n addition, it is interesting to look into the p-values of statistical significance tests for each concept. We say, that we reject null hypothesis, if the p-value for concept's TCAV scores is smaller than 0.05. This indicates that the concept is important for model prediction.\n",
        "\n",
        "We label concept populations as overlapping if p-value > 0.05 otherwise disjoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OPDyc7w91HT"
      },
      "outputs": [],
      "source": [
        "def get_pval(scores, experimental_sets, score_layer, score_type, alpha=0.05, print_ret=False):\n",
        "\n",
        "    P1 = assemble_scores(scores, experimental_sets, 0, score_layer, score_type)\n",
        "    P2 = assemble_scores(scores, experimental_sets, 1, score_layer, score_type)\n",
        "\n",
        "    if print_ret:\n",
        "        print('P1[mean, std]: ', format_float(np.mean(P1)), format_float(np.std(P1)))\n",
        "        print('P2[mean, std]: ', format_float(np.mean(P2)), format_float(np.std(P2)))\n",
        "\n",
        "    _, pval = ttest_ind(P1, P2)\n",
        "\n",
        "    if print_ret:\n",
        "        print(\"p-values:\", format_float(pval))\n",
        "\n",
        "    if pval < alpha:    # alpha value is 0.05 or 5%\n",
        "        relation = \"Disjoint\"\n",
        "        if print_ret:\n",
        "            print(\"Disjoint\")\n",
        "    else:\n",
        "        relation = \"Overlap\"\n",
        "        if print_ret:\n",
        "            print(\"Overlap\")\n",
        "\n",
        "    return P1, P2, format_float(pval), relation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqG6EjX492f1"
      },
      "source": [
        "We now run the TCAV and obtain the scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5PVug5o93tI"
      },
      "outputs": [],
      "source": [
        "# Run TCAV\n",
        "scores = mytcav.interpret(zebra_tensors, experimental_sets, zebra_ind, n_steps=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLZ4zwf895vN"
      },
      "source": [
        "We can present the distribution of tcav scores using boxplots and the p-values indicating whether TCAV scores of those concepts are overlapping or disjoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDmHiICv95ee"
      },
      "outputs": [],
      "source": [
        "n = 4\n",
        "def show_boxplots(layer, metric='sign_count'):\n",
        "\n",
        "    def format_label_text(experimental_sets):\n",
        "        concept_id_list = [exp.name if i == 0 else \\\n",
        "                             exp.name.split('_')[0] for i, exp in enumerate(experimental_sets[0])]\n",
        "        return concept_id_list\n",
        "\n",
        "    n_plots = 2\n",
        "\n",
        "    fig, ax = plt.subplots(1, n_plots, figsize = (25, 7 * 1))\n",
        "    fs = 18\n",
        "    for i in range(n_plots):\n",
        "        esl = experimental_sets[i * n : (i+1) * n]\n",
        "        P1, P2, pval, relation = get_pval(scores, esl, layer, metric)\n",
        "\n",
        "        ax[i].set_ylim([0, 1])\n",
        "        ax[i].set_title(layer + \"-\" + metric + \" (pval=\" + str(pval) + \" - \" + relation + \")\", fontsize=fs)\n",
        "        ax[i].boxplot([P1, P2], showfliers=True)\n",
        "\n",
        "        ax[i].set_xticklabels(format_label_text(esl), fontsize=fs)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCg3Lgr19943"
      },
      "source": [
        "Below box plots visualize the distribution of TCAV scores for two pairs of concepts in three different layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7xTnyZe99uY"
      },
      "outputs": [],
      "source": [
        "show_boxplots (\"inception4c\")\n",
        "show_boxplots (\"inception4d\")\n",
        "show_boxplots (\"inception4e\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJUUyhAE/Qc15ypcRq/XVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}